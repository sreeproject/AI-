{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreeproject/AI-/blob/main/Brain_Tumor_Sample_ML_Submission_Template_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Brain Tumor MRI Image Classification\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification/Supervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to develop a deep learning-based solution for classifying brain MRI images into multiple categories according to tumor type. It involves building a custom CNN model from scratch and enhancing performance through transfer learning using pretrained models. The project also includes deploying a user-friendly Streamlit web application to enable real-time tumor type predictions from uploaded MRI images.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Brain Tumor MRI Image Classification"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import dataset,dataloader\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "to-y-_6ac8cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4I-GR5-mePBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = r'/content/drive/MyDrive/Tumour'\n",
        "print(\"dataset exists:\", os.path.exists(root))\n",
        "\n",
        "if os.path.exists(root):\n",
        "    print(\"Subfolders:\")\n",
        "    for sub in os.listdir(root):\n",
        "        print(\"  âž¤\", sub)"
      ],
      "metadata": {
        "id": "Z9RqEDiIc7ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "FidazFZ1U-P1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y49SUxdjW2t-"
      },
      "outputs": [],
      "source": [
        "os.listdir(\"/content/drive/MyDrive/Tumour/train\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/Tumour/valid\")"
      ],
      "metadata": {
        "id": "0VtCM3WYvSzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHfFBuW4vWTp"
      },
      "outputs": [],
      "source": [
        "os.listdir(\"/content/drive/MyDrive/Tumour/test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6MQDwSCdeftY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img=image.load_img('/content/drive/MyDrive/Tumour/train/glioma/Tr-gl_0011_jpg.rf.61e213cb5a0f97fedd1bacd0428c0133.jpg')\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "cMjgD9taegaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yjiAvcOy91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "path = r'/content/drive/MyDrive/Tumour/valid/glioma/*.jpg'\n",
        "\n",
        "files = glob.glob(path)\n",
        "if files:\n",
        "    img_path = files[0]  # just pick the first one\n",
        "    img = image.load_img(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(os.path.basename(img_path))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found in folder.\")\n"
      ],
      "metadata": {
        "id": "hySWUI1tc7LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img=image.load_img('/content/drive/MyDrive/Tumour/test/glioma/Tr-gl_0016_jpg.rf.99746694ea97fe0b73108832b462d48e.jpg')\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "NtpW9Dt7WC7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZp5W2e-ViUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "t8ZBue8MVjBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img('/content/drive/MyDrive/Tumour/test/glioma/Tr-gl_0016_jpg.rf.99746694ea97fe0b73108832b462d48e.jpg')\n",
        "img_array = np.array(img) # Convert PIL Image to NumPy array\n",
        "print(img_array.shape) # Access the shape of the NumPy array"
      ],
      "metadata": {
        "id": "MX59-Zjkdw9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z9TT6k87PhLd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9j08ZmZqc7hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "aihHLxwVWB30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir1 = '/content/drive/MyDrive/Tumour/train/*/*.jpg'\n",
        "train = []\n",
        "for f in glob.glob(data_dir1, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        train.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(train)}\")"
      ],
      "metadata": {
        "id": "QVun60Upfou5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXlkgBb7fo12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir2 = '/content/drive/MyDrive/Tumour/valid/*/*.jpg'\n",
        "valid = []\n",
        "for f in glob.glob(data_dir2, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        valid.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(valid)}\")"
      ],
      "metadata": {
        "id": "5VRgQNnxUruZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir3 = '/content/drive/MyDrive/Tumour/test/*/*.jpg'\n",
        "test = []\n",
        "for f in glob.glob(data_dir3, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        test.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(test)}\")"
      ],
      "metadata": {
        "id": "y-kaFDZKYcpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train contains 1695 images, valid contains 502 images and test contains 246 images."
      ],
      "metadata": {
        "id": "REC6rwMKMvme"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxW3Cpcgvs9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path = \"/content/drive/MyDrive/Tumour/train\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts = pd.DataFrame(list(class_counts.items()), columns=['Tumor_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_counts, x='Tumor_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (Tumor Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "7jpoe34iWchV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts['Image_Count'], labels=df_counts['Tumor_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"Tumor Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tuh8u5DGJpM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path = \"/content/drive/MyDrive/Tumour/valid\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts1 = pd.DataFrame(list(class_counts.items()), columns=['Tumor_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_counts, x='Tumor_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (Tumor Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts1)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "rlBVp3LkJwHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts1['Image_Count'], labels=df_counts1['Tumor_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"Tumor Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3z4HpypEJ4oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path = \"/content/drive/MyDrive/Tumour/test\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts2 = pd.DataFrame(list(class_counts.items()), columns=['Tumor_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_counts, x='Tumor_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (Tumor Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts2)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "9Pz0B6vHJ6jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts['Image_Count'], labels=df_counts2['Tumor_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"Tumor Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MXyIMVubLy8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Yyi7I4FL8yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/brain\"\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "zgKHxD2n7NcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resize, normalize, augment train)\n",
        "import pathlib\n",
        "\n",
        "data_dir='/content/drive/MyDrive/Tumour'\n",
        "#train_dir = os.path.join(dataset_dir, 'train')\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shift (10%)\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),   # Random brightness & contrast\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),    # Random zoom (scale)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ],
      "metadata": {
        "id": "p1ymtLtAWd1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUsFv9i2lRp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dir = os.path.join(data_dir, 'valid')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "valid_dataset = ImageFolder(valid_dir, transform=transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Class names\n",
        "classes = train_dataset.classes\n",
        "print(\"Train Classes:\", classes)\n",
        "classes1 = valid_dataset.classes\n",
        "print(\"valid Classes:\", classes1)\n",
        "classes2 = test_dataset.classes\n",
        "print(\"test Classes:\", classes2)"
      ],
      "metadata": {
        "id": "vQu2iVQK8iEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from training dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "1v9BOLwEAgLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcLsFzUFOH7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from valid dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(valid_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "JUED_HcEBzVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT3TtJ0aOUer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from test dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "KIzCPxpVB7nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5ScqwgGpuc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-3ctO27W2i1"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath('train'), transform=transform)\n",
        "train_set.transform\n",
        "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath('valid'), transform=transform)\n",
        "val_set.transform\n",
        "test_set = torchvision.datasets.ImageFolder(data_dir.joinpath('test'), transform=transform)\n",
        "test_set.transform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "id": "j_bqbIk579pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set"
      ],
      "metadata": {
        "id": "ZoLQzkTp8oAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "XxHhAysI8r4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrE6kLgk8vHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ2eoeHfW2dh"
      },
      "outputs": [],
      "source": [
        "img, label = train_set[1000]\n",
        "plt.imshow(img.permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UniX3mDh8u88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle=True,num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "_Tw8QBLFqV3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[0].shape"
      ],
      "metadata": {
        "id": "q7-wvt3e9oPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_loader))[0].shape"
      ],
      "metadata": {
        "id": "pnnS0iXfqVvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(val_loader))[0].shape"
      ],
      "metadata": {
        "id": "UZfulps89Y3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ow-1k5QW-whi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model building\n",
        "#### Custom CNN"
      ],
      "metadata": {
        "id": "W8dBeTjQidWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "\n",
        "    #Conv 1: 224x224 input\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0) # (224-5+1)/1 = 220\n",
        "\n",
        "    #Max Pool 1: 220x220 input\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=2) # 220/2 = 110\n",
        "\n",
        "    #Conv 2: 110x110 input\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0) # (110-5+1)/1 = 106\n",
        "\n",
        "    #Max Pool 2: 106x106 input\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=2) # 106/2 = 53\n",
        "\n",
        "    #Conv 3: 53x53 input\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=0) # (53-5+1)/1 = 49\n",
        "\n",
        "    #Max Pool 3: 49x49 input\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=2) # 49/2 = 24 (floor)\n",
        "\n",
        "    #Conv 4: 24x24 input\n",
        "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=0) # (24-5+1)/1 = 20\n",
        "\n",
        "    #Max Pool 4: 20x20 input\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=2) # 20/2 = 10\n",
        "\n",
        "    #Activation Function\n",
        "    self.leakyRelu = nn.LeakyReLU()\n",
        "\n",
        "    # Calculate flattened size dynamically\n",
        "    self._to_linear = 128 * 10 * 10 # Output channels of last conv * final spatial dimensions\n",
        "\n",
        "    #Fully connected Layer 1\n",
        "    self.fc1 = nn.Linear(self._to_linear, 1024)\n",
        "\n",
        "    #Fully connected Layer 2\n",
        "    self.fc2 = nn.Linear(1024, len(classes)) # Use len(classes) for the number of output classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    #Layer 1\n",
        "    out = self.leakyRelu(self.conv1(x))\n",
        "    out = self.maxpool1(out)\n",
        "\n",
        "    #Layer 2\n",
        "    out = self.leakyRelu(self.conv2(out))\n",
        "    out = self.maxpool2(out)\n",
        "\n",
        "    #Layer 3\n",
        "    out = self.leakyRelu(self.conv3(out))\n",
        "    out = self.maxpool3(out)\n",
        "\n",
        "    #Layer 4\n",
        "    out = self.leakyRelu(self.conv4(out))\n",
        "    out = self.maxpool4(out)\n",
        "\n",
        "    #flatten\n",
        "    out = out.view(out.size(0), -1)\n",
        "\n",
        "    # Linear Function\n",
        "    out = self.leakyRelu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "i_E_vpqm-xWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWGP9Cqk-wRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training CNN\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Class names (moved from cell vQu2iVQK8iEl)\n",
        "train_dataset = ImageFolder(\"/content/drive/MyDrive/Tumour/train\", transform=transform) # Assuming transform is defined\n",
        "classes = train_dataset.classes\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "model = CNNModel()\n",
        "error = nn.CrossEntropyLoss()\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ],
      "metadata": {
        "id": "3sQQlSYw_B3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDtXfqK5_Yvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "test_loss_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "# Move model and criterion to device\n",
        "model.to(device)\n",
        "error.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    test_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = error(outputs, labels)\n",
        "        train_loss += loss.item() * images.size(0) # Multiply by batch size for correct average later\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(\"Loss in Iteration:\", i, \":\", loss.item()) # Optional: print loss per iteration\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            v_loss = error(outputs, labels)\n",
        "            val_loss += v_loss.item() * images.size(0) # Multiply by batch size\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    # Test loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs1 = model(images) # Use outputs1 for test\n",
        "            tes_loss = error(outputs1, labels) # Use outputs1 here\n",
        "            test_loss += tes_loss.item() * images.size(0) # Multiply by batch size\n",
        "\n",
        "            _, predicted1 = torch.max(outputs1.data, 1) # Use predicted1 for test\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted1 == labels).sum().item()\n",
        "\n",
        "\n",
        "    # Calculate average losses and accuracies\n",
        "    avg_train_loss = train_loss / total_train\n",
        "    avg_val_loss = val_loss / total_val\n",
        "    avg_test_loss = test_loss / total_test\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "\n",
        "    # Append to lists\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    val_loss_list.append(avg_val_loss)\n",
        "    test_loss_list.append(avg_test_loss)\n",
        "    accuracy_list.append(train_accuracy) # Store train, val, test accuracy for the epoch\n",
        "    accuracy_list.append(val_accuracy)\n",
        "    accuracy_list.append(test_accuracy)\n",
        "\n",
        "\n",
        "    # Step the scheduler based on validation loss\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_val_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Valid Acc: {val_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "wlsmIX41_aCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In the case of CNN i got the test accc and valid acc is 73%. which is a littile bit low and losses are there. So pretrained the model"
      ],
      "metadata": {
        "id": "zEZQc65TJJjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'classes' is defined, e.g., as a list of class names\n",
        "# For demonstration purposes, let's define a dummy 'classes'\n",
        "classes = ['class','class1', 'class2', 'class3']"
      ],
      "metadata": {
        "id": "0JuOAJTTrjwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=len(classes)"
      ],
      "metadata": {
        "id": "WJL-a1ajO2-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RjeUDIJyx1Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transfer Learning\n",
        "\n",
        "###Load pretrained models (Example : ResNet50)\n"
      ],
      "metadata": {
        "id": "OzyqLMzCTPLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final layer\n",
        "resnet_model.fc = nn.Sequential(\n",
        "    nn.Linear(resnet_model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(512, num_classes)\n",
        ")\n",
        "\n",
        "resnet_model = resnet_model.to(device)"
      ],
      "metadata": {
        "id": "PePYmtK9x1V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnet_model.fc.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "TOKd1urCx1Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "def train_model(model, train_loader, val_loader,test_loader, epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "1SNgpsZRx1a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(resnet_model, train_loader, valid_loader,test_loader, epochs=10)"
      ],
      "metadata": {
        "id": "dKvk74nGx1dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In the case of resnet 50 i got the  Accuracy  84% and loss is really very less here. Pretrained the model to get very high accuracy"
      ],
      "metadata": {
        "id": "TMhGs65f-dIf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zjhImkATsZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Model Training\n",
        "\n",
        "\n",
        "#####Train both custom CNN and transfer learning models.\n"
      ],
      "metadata": {
        "id": "jyoiLD5vs3AO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NoFCJkoRUfSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Custom CNN Architecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 256)  # assuming input image size is 224x224\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8vOpBrLb1YS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unified Training Function (for Custom CNN or ResNet)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = np.inf # Changed np.Inf to np.inf\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def save_checkpoint(model, path='best_model.pth'):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved at {path}\")\n",
        "\n",
        "def train_with_callbacks(model, criterion, optimizer, train_loader, val_loader, device,\n",
        "                         num_epochs=25, early_stopping=None, checkpoint_path='best_model.pth'):\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_loss = float('inf')\n",
        "    best_test_loss = float('inf')  # Initialize best_test_loss\n",
        "\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    test_loss_history =[]\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_train_loss = train_loss / total\n",
        "        epoch_train_acc = correct / total\n",
        "        train_loss_history.append(epoch_train_loss)\n",
        "        train_acc_history.append(epoch_train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        epoch_val_loss = val_loss / total\n",
        "        epoch_val_acc = correct / total\n",
        "        val_loss_history.append(epoch_val_loss)\n",
        "        val_acc_history.append(epoch_val_acc)\n",
        "\n",
        "\n",
        "\n",
        "        # Test phase\n",
        "        model.eval()\n",
        "        test_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader: # Changed from val_loader to test_loader\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        epoch_test_loss = test_loss / total\n",
        "        epoch_test_acc = correct / total\n",
        "        test_loss_history.append(epoch_test_loss) # Corrected append\n",
        "        test_acc_history.append(epoch_test_acc) # Corrected append\n",
        "\n",
        "        print(f\"Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f}\")\n",
        "        print(f\"Val   Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.4f}\")\n",
        "        print(f\"Test   Loss: {epoch_test_loss:.4f}, Acc: {epoch_test_acc:.4f}\")\n",
        "\n",
        "\n",
        "        # Checkpoint\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            save_checkpoint(model, checkpoint_path)\n",
        "        if epoch_test_loss < best_test_loss:\n",
        "            best_test_loss = epoch_test_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            save_checkpoint(model, checkpoint_path)\n",
        "\n",
        "\n",
        "        # Early Stopping\n",
        "        if early_stopping:\n",
        "            early_stopping(epoch_val_loss)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping triggered based on validation loss.\")\n",
        "                break\n",
        "        if early_stopping:\n",
        "            early_stopping(epoch_test_loss)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping triggered based on test loss.\")\n",
        "                break\n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss_history, val_loss_history,test_loss_history, train_acc_history, val_acc_history,test_acc_history"
      ],
      "metadata": {
        "id": "iKLF_vJ1RsKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Both Models\n",
        "# Custom CNN (Example)\n",
        "#num_classes = len(classes)  # classes = train_dataset.classes\n",
        "#cnn_model = CNNModel(num_classes).to(device)\n",
        "cnn_model = CustomCNN(num_classes).to(device)\n",
        "\n",
        "optimizer_cnn = torch.optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "cnn_model, cnn_train_loss, cnn_val_loss,cnn_test_loss, cnn_train_acc, cnn_val_acc,cnn_test_acc = train_with_callbacks(\n",
        "    cnn_model,\n",
        "    nn.CrossEntropyLoss(),\n",
        "    optimizer_cnn,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        "    early_stopping=early_stopper,\n",
        "    checkpoint_path='cnn_best_model.pth'\n",
        ")"
      ],
      "metadata": {
        "id": "EjtWkGJPRp7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evr-iutqRrZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3p6qVncuMJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Assuming you have a custom dataset and loaders, these are placeholders\n",
        "# for demonstration. Replace them with your actual dataset and loaders.\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Placeholder for your data and loaders\n",
        "# You should define your actual train_dataset, valid_dataset, etc.\n",
        "# For example:\n",
        "# from torchvision.datasets import ImageFolder\n",
        "# from torch.utils.data import DataLoader\n",
        "# train_dataset = ImageFolder('path/to/train', transform=your_transform)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# num_classes = len(train_dataset.classes)\n",
        "num_classes = 10 # Example number of classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---\n",
        "# 1. Load pretrained ResNet50\n",
        "# ---\n",
        "# Use a more modern weight as it often performs better\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "resnet = models.resnet50(weights=weights)\n",
        "\n",
        "# ---\n",
        "# 2. Adjusting the fine-tuning strategy\n",
        "# ---\n",
        "# Freeze all layers first\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last two blocks (layer3 and layer4) for more effective fine-tuning.\n",
        "# This provides a better balance between feature reuse and task-specific learning.\n",
        "# Fine-tuning only layer4 and fc might not be enough to learn the new features well.\n",
        "for name, param in resnet.named_parameters():\n",
        "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# ---\n",
        "# 3. Replace final layer for custom classification\n",
        "# ---\n",
        "# This part is correct, but let's make it a more robust replacement using Sequential\n",
        "resnet.fc = nn.Sequential(\n",
        "    nn.Linear(resnet.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, num_classes)\n",
        ")\n",
        "\n",
        "# ---\n",
        "# 4. Move model to GPU\n",
        "# ---\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# ---\n",
        "# 5. Use optimizer with a better approach\n",
        "# ---\n",
        "# Use a more sophisticated optimizer like AdamW which often performs better than Adam\n",
        "# and a lower learning rate for the frozen layers while a higher one for the new layers.\n",
        "# We also use a separate optimizer for the new layers to have more control.\n",
        "optimizer_resnet = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, resnet.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "\n",
        "# ---\n",
        "# 6. Define loss function\n",
        "# ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ---\n",
        "# 7. Add learning rate scheduler\n",
        "# ---\n",
        "# Reduce the learning rate as training progresses to avoid overshooting the minimum.\n",
        "# This helps the model converge more smoothly and improves accuracy.\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_resnet, 'max', patience=5, factor=0.1)\n",
        "\n",
        "# ---\n",
        "# 8. Define a robust training function with data augmentation\n",
        "# ---\n",
        "# Data augmentation is critical for preventing overfitting, especially with smaller datasets.\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Your custom train_model function should be updated to include the scheduler logic.\n",
        "# The `train_model` function you're using is not provided, but here is an example\n",
        "# of how the training loop should be structured to use the scheduler.\n",
        "def improved_train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs, device):\n",
        "    best_val_accuracy = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Step the scheduler based on validation accuracy\n",
        "        scheduler.step(val_accuracy)\n",
        "\n",
        "        # Save the best model\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'resnet_best_model.pth')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "z_ZkjJ8AuMQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "improved_train_model(\n",
        "  model=resnet,\n",
        " train_loader=train_loader,\n",
        " val_loader=valid_loader,\n",
        "  optimizer=optimizer_resnet,\n",
        "  criterion=criterion,\n",
        "  scheduler=scheduler,\n",
        "  epochs=10,\n",
        "  device=device\n",
        ")"
      ],
      "metadata": {
        "id": "6oMJUwh11cBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model resnet50 i got 94% accuracy which is good. Here i got more accuracy uesing resnet50 compare to custom CNN"
      ],
      "metadata": {
        "id": "b9Rd9Df-S3SG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKq9C8_nS1Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model Evaluation\n",
        "\n",
        "\n",
        "###Evaluate models using metrics like accuracy, precision, recall, F1-score, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "-n3HG1CGvwPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    print(\"Accuracy:\", round(acc, 4))\n",
        "    print(\"Precision:\", round(precision, 4))\n",
        "    print(\"Recall:\", round(recall, 4))\n",
        "    print(\"F1 Score:\", round(f1, 4))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "c6H7l0yzvv6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_ERdXsMbQUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader,device)"
      ],
      "metadata": {
        "id": "Wk5u6043bS2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(resnet, test_loader,device)"
      ],
      "metadata": {
        "id": "Xlr0w8auvvt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Comparison\n",
        "\n",
        "\n",
        "# Compare results of custom CNN vs pretrained models.\n",
        "\n",
        "\n",
        "#Identify the most accurate, efficient, and reliable model for deployment.\n"
      ],
      "metadata": {
        "id": "1tH2n-lUyKXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Custom CNN', 'ResNet50']\n",
        "accuracies = [73, 96]\n",
        "f1_scores = [70, 95]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bar_width = 0.35\n",
        "x = range(len(models))\n",
        "\n",
        "plt.bar(x, accuracies, width=bar_width, label='Accuracy')\n",
        "plt.bar([i + bar_width for i in x], f1_scores, width=bar_width, label='F1-score')\n",
        "plt.xticks([i + bar_width / 2 for i in x], models)\n",
        "plt.ylabel('Score (%)')\n",
        "plt.title('Model Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqMlnJH0yJAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph titled \"Model Comparison\" showcases the performance of two deep learning modelsâ€”Custom CNN and ResNet50â€”based on accuracy and F1-score metrics. Custom CNN reaches approximately 73% accuracy and70% F1-score, while ResNet50 significantly outperforms it with about 96% accuracy and 95% F1-score. This visualization clearly highlights ResNet50â€™s superior performance, making it the stronger choice for this classification task."
      ],
      "metadata": {
        "id": "0FvUgLbUcmHp"
      }
    }
  ]
}