{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreeproject/AI-/blob/main/Copy_of_Multifishclassification__Sample_ML_Submission_Template_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Multiclass Fish Image Classification\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification/Supervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on classifying fish images into multiple categories using deep learning models. The task involves training a CNN from scratch and leveraging transfer learning with pre-trained models to enhance performance. The project also includes saving models for later use and deploying a Streamlit application to predict fish categories from user-uploaded images.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass Fish Image Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import dataset,dataloader\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "to-y-_6ac8cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "DAjjP_4FDXnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4I-GR5-mePBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/MultclassFish/datasets.zip'  # üîÅ Change this\n",
        "extract_path = '/content/drive/MyDrive/MultclassFish/datasets/datasets'  # Destination folder\n",
        "\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "lvhtWUjqPofb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List extracted folders/files\n",
        "os.listdir(extract_path)"
      ],
      "metadata": {
        "id": "0doQq_88QFcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = '/content/drive/MyDrive/MultclassFish/datasets/datasets/train'\n",
        "val_dir = '/content/drive/MyDrive/MultclassFish/datasets/datasets/val'\n",
        "test_dir = '/content/drive/MyDrive/MultclassFish/datasets/datasets/test'"
      ],
      "metadata": {
        "id": "-JukHdlWQpEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_path)"
      ],
      "metadata": {
        "id": "nGzOhTEluUrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/MultclassFish/datasets/datasets')"
      ],
      "metadata": {
        "id": "iM9SFA__TWpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets view"
      ],
      "metadata": {
        "id": "Fs0XInVDWhf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category1=os.listdir(train_dir)\n",
        "category1"
      ],
      "metadata": {
        "id": "0O-YmbMzVXlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category2=os.listdir(val_dir)\n",
        "category2"
      ],
      "metadata": {
        "id": "ibHt5dQRVfuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category3=os.listdir(test_dir)\n",
        "category3"
      ],
      "metadata": {
        "id": "Gnda0R0IVjh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Data Generators\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Just rescaling for validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "HlINE-vnRGrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Data from Folders\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # Resize images\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # or 'binary' for 2 classes\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "fF5iIyfyRP0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick train and Display Sample Images\n",
        "from tensorflow.keras.preprocessing.image import load_img # Add this import\n",
        "sample_class = category1[0]  # You can change this to any category name\n",
        "image_folder = os.path.join(train_dir, sample_class)\n",
        "image_files = os.listdir(image_folder)\n",
        "\n",
        "# Show first 5 images\n",
        "for i in range(5):\n",
        "    img_path = os.path.join(image_folder, image_files[i])\n",
        "    img = load_img(img_path, target_size=(224, 224))  # Resize for uniformity\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {sample_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6MQDwSCdeftY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJ0fKUGoYS8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick val and Display Sample Images\n",
        "sample_class = category2[0]  # You can change this to any category name\n",
        "image_folder = os.path.join(val_dir, sample_class)\n",
        "image_files = os.listdir(image_folder)\n",
        "\n",
        "# Show first 5 images\n",
        "for i in range(5):\n",
        "    img_path = os.path.join(image_folder, image_files[i])\n",
        "    img = load_img(img_path, target_size=(224, 224))  # Resize for uniformity\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {sample_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3tvj5l3HYToc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dc0GvIL5Yk67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick test and Display Sample Images\n",
        "sample_class = category3[0]  # You can change this to any category name\n",
        "image_folder = os.path.join(test_dir, sample_class)\n",
        "image_files = os.listdir(image_folder)\n",
        "\n",
        "# Show first 5 images\n",
        "for i in range(5):\n",
        "    img_path = os.path.join(image_folder, image_files[i])\n",
        "    img = load_img(img_path, target_size=(224, 224))  # Resize for uniformity\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {sample_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h2V8csqxYlbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Random Images from All Classes - train\n",
        "\n",
        "import random\n",
        "\n",
        "for label in category1:\n",
        "    img_folder = os.path.join(train_dir, label)\n",
        "    img_file = random.choice(os.listdir(img_folder))\n",
        "    img_path = os.path.join(img_folder, img_file)\n",
        "\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TkGnl9SrYydM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7pMD4uBZCcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Random Images from All Classes - val\n",
        "\n",
        "import random\n",
        "\n",
        "for label in category1:\n",
        "    img_folder = os.path.join(val_dir, label)\n",
        "    img_file = random.choice(os.listdir(img_folder))\n",
        "    img_path = os.path.join(img_folder, img_file)\n",
        "\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0sa0VG9eZDJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Or29IWnkZHXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show Random Images from All Classes - test\n",
        "\n",
        "import random\n",
        "\n",
        "for label in category1:\n",
        "    img_folder = os.path.join(test_dir, label)\n",
        "    img_file = random.choice(os.listdir(img_folder))\n",
        "    img_path = os.path.join(img_folder, img_file)\n",
        "\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Gf-FqXhEZH8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yjiAvcOy91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "path = r'/content/drive/MyDrive/MultclassFish/datasets/datasets/train/animal fish/*.jpg'\n",
        "\n",
        "files = glob.glob(path)\n",
        "if files:\n",
        "    img_path = files[0]  # just pick the first one\n",
        "    img = image.load_img(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(os.path.basename(img_path))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found in folder.\")\n"
      ],
      "metadata": {
        "id": "hySWUI1tc7LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZp5W2e-ViUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "t8ZBue8MVjBf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9j08ZmZqc7hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "aihHLxwVWB30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir1 = '/content/drive/MyDrive/MultclassFish/datasets/datasets/train/*/*.jpg'\n",
        "train = []\n",
        "for f in glob.glob(data_dir1, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        train.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(train)}\")"
      ],
      "metadata": {
        "id": "QVun60Upfou5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXlkgBb7fo12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir2 = '/content/drive/MyDrive/MultclassFish/datasets/datasets/val/*/*.jpg'\n",
        "valid = []\n",
        "for f in glob.glob(data_dir2, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        valid.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(valid)}\")"
      ],
      "metadata": {
        "id": "5VRgQNnxUruZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to images inside extracted folder\n",
        "\n",
        "data_dir3 = '/content/drive/MyDrive/MultclassFish/datasets/datasets/test/*/*.jpg'\n",
        "test = []\n",
        "for f in glob.glob(data_dir3, recursive=True):\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        test.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load: {f}\")\n",
        "\n",
        "print(f\"Total images loaded: {len(test)}\")"
      ],
      "metadata": {
        "id": "y-kaFDZKYcpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train contains 1695 images, valid contains 502 images and test contains 246 images."
      ],
      "metadata": {
        "id": "REC6rwMKMvme"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxW3Cpcgvs9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path = \"/content/drive/MyDrive/MultclassFish/datasets/datasets/train\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts = pd.DataFrame(list(class_counts.items()), columns=['fish_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_counts, x='fish_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (Fish Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"fish Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "7jpoe34iWchV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts['Image_Count'], labels=df_counts['fish_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"fish Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tuh8u5DGJpM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path1 = \"/content/drive/MyDrive/MultclassFish/datasets/datasets/val\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path1):\n",
        "    class_dir = os.path.join(dataset_path1, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts2 = pd.DataFrame(list(class_counts.items()), columns=['fish_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_counts2, x='fish_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (fish Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Fish Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts2)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "rlBVp3LkJwHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts2['Image_Count'], labels=df_counts2['fish_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"fish Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3z4HpypEJ4oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "dataset_path2 = \"/content/drive/MyDrive/MultclassFish/datasets/datasets/test\"  # or any folder containing class subfolders\n",
        "\n",
        "# Step 1: Collect class-wise image counts and image resolutions\n",
        "class_counts = defaultdict(int)\n",
        "image_sizes = []\n",
        "\n",
        "# Walk through the dataset\n",
        "for class_name in os.listdir(dataset_path2):\n",
        "    class_dir = os.path.join(dataset_path2, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, image_name)\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                  class_counts[class_name] += 1\n",
        "                  image_sizes.append(img.size)\n",
        "            except Exception as e:\n",
        "                  print(f\"Skipping image: {img_path} | Error: {e}\")\n",
        "\n",
        "# Step 2: Convert to DataFrame\n",
        "df_counts3 = pd.DataFrame(list(class_counts.items()), columns=['Tumor_Type', 'Image_Count'])\n",
        "df_sizes = pd.DataFrame(image_sizes, columns=['Width', 'Height'])\n",
        "\n",
        "# Step 3: Plot Class Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data = df_counts3, x='Tumor_Type', y='Image_Count', palette='Set2')\n",
        "plt.title(\"Class Distribution (fish Types)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"fish Type\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Plot Image Resolution Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df_sizes['Width'], color='skyblue', kde=True, label='Width', bins=30)\n",
        "sns.histplot(df_sizes['Height'], color='orange', kde=True, label='Height', bins=30)\n",
        "plt.title(\"Image Resolution Distribution\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Print summary statistics\n",
        "print(\"Class Distribution:\\n\", df_counts3)\n",
        "print(\"\\nImage Resolution Stats:\\n\", df_sizes.describe())"
      ],
      "metadata": {
        "id": "9Pz0B6vHJ6jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(df_counts3['Image_Count'], labels=df_counts3['Tumor_Type'], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set2'))\n",
        "plt.title(\"fish Class Distribution (Pie Chart)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MXyIMVubLy8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Yyi7I4FL8yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "data_dir='/content/drive/MyDrive/MultclassFish/datasets/datasets/'\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "metadata": {
        "id": "zgKHxD2n7NcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resize, normalize, augment train)\n",
        "import pathlib\n",
        "\n",
        "#train_dir = os.path.join(dataset_dir, 'train')\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shift (10%)\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),   # Random brightness & contrast\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),    # Random zoom (scale)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ],
      "metadata": {
        "id": "p1ymtLtAWd1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUsFv9i2lRp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dir = os.path.join(data_dir, 'val')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "val_dataset = ImageFolder(val_dir, transform=transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Class names\n",
        "classes = train_dataset.classes\n",
        "print(\"Train Classes:\", classes)\n",
        "classes1 = val_dataset.classes\n",
        "print(\"valid Classes:\", classes1)\n",
        "classes2 = test_dataset.classes\n",
        "print(\"test Classes:\", classes2)"
      ],
      "metadata": {
        "id": "vQu2iVQK8iEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from training dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "1v9BOLwEAgLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WcLsFzUFOH7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from valid dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(val_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "JUED_HcEBzVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT3TtJ0aOUer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize augmented images from test dataset.\n",
        "def imshow(img):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one batch\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "for i in range(5):\n",
        "    imshow(images[i])"
      ],
      "metadata": {
        "id": "KIzCPxpVB7nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5ScqwgGpuc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-3ctO27W2i1"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath('train'), transform=transform)\n",
        "train_set.transform\n",
        "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath('val'), transform=transform)\n",
        "val_set.transform\n",
        "test_set = torchvision.datasets.ImageFolder(data_dir.joinpath('test'), transform=transform)\n",
        "test_set.transform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "id": "j_bqbIk579pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set"
      ],
      "metadata": {
        "id": "ZoLQzkTp8oAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set"
      ],
      "metadata": {
        "id": "XxHhAysI8r4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrE6kLgk8vHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ2eoeHfW2dh"
      },
      "outputs": [],
      "source": [
        "img, label = train_set[1000]\n",
        "plt.imshow(img.permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UniX3mDh8u88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 #model gets data in batches (instead of one image at a time).\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle=True,num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "_Tw8QBLFqV3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[0].shape"
      ],
      "metadata": {
        "id": "q7-wvt3e9oPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch of 64 images, 3 is the channel RGB,224*224 pixels is the shape"
      ],
      "metadata": {
        "id": "X3mXWJDQ4TSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_loader))[0].shape"
      ],
      "metadata": {
        "id": "pnnS0iXfqVvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(val_loader))[0].shape"
      ],
      "metadata": {
        "id": "UZfulps89Y3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ow-1k5QW-whi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model building\n",
        "#### Custom CNN"
      ],
      "metadata": {
        "id": "W8dBeTjQidWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "_260mz705KA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Downsamples by 2x\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 256)  # Depends on input image size\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # [64, 32, 112, 112]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # [64, 64, 56, 56]\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hWGP9Cqk-wRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Model\n",
        "num_classes = len(train_set.classes)  # Automatically gets number of categories\n",
        "model = SimpleCNN(num_classes)"
      ],
      "metadata": {
        "id": "LkqCulTF5mby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Setup\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "uFJ6shRp5mgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training each loop\n",
        "for epoch in range(5):  # Increase this for better accuracy\n",
        "    model.train()\n",
        "    #find train accuracy\n",
        "    running_loss = 0.0\n",
        "    total_train = 0\n",
        "    correct_train=0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_train += labels.size(0)\n",
        "    correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "   # find val accuracy\n",
        "    running_loss1 = 0.0\n",
        "    total_val = 0\n",
        "    correct_val=0\n",
        "\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss1 += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_val += labels.size(0)\n",
        "    correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    #find test accuracy\n",
        "    running_loss2 = 0.0\n",
        "    total_test = 0\n",
        "    correct_test=0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss2 += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_test += labels.size(0)\n",
        "    correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, train_accuracy:{ 100 * correct_train / total_train}\")\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss1/len(val_loader)}, val_accuracy:{ 100 * correct_val / total_val}\")\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss2/len(train_loader)}, test_accuracy:{ 100 * correct_test / total_test}\")"
      ],
      "metadata": {
        "id": "YzPFeG425mkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vygQ4GIZgiUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In the case of CNN i got the test accc 98% and valid acc is 100% and train accuracy is 94%. Test accuracy and train accuracy are very good So pretrained the model. But the val accurcy shows overfitting. The losses are really very less here. So pretrained the model to get best result"
      ],
      "metadata": {
        "id": "GW3vg7dygqzg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDnfVzp05mnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULijd2LUJz35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vgg16"
      ],
      "metadata": {
        "id": "qAFZs3z5J4Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained VGG16\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "#Freeze Pretrained Layers (Optional)\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False\n",
        "#Modify the Classifier\n",
        "#need to change the final layer to match your number of classes:\n",
        "num_classes = len(train_set.classes)  # Automatically detect number of output classes\n",
        "\n",
        "vgg16.classifier[6] = nn.Linear(4096, num_classes)  # Replace final FC layer\n",
        "\n",
        "#Training Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "TZ-CEzDqJz9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "\n",
        "for epoch in range(5):  # Increase for better performance\n",
        "    vgg16.train()\n",
        "    running_loss = 0.0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    # for train\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    running_loss1 = 0.0\n",
        "    total_val = 0\n",
        "    correct_val = 0\n",
        "    #for val\n",
        "    # for train\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss1 += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_val += labels.size(0)\n",
        "        correct_val+= (predicted == labels).sum().item()\n",
        "\n",
        "    running_loss2 = 0.0\n",
        "    total_test = 0\n",
        "    correct_test = 0\n",
        "    #for test\n",
        "\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss2 += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test+= (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {(100 * correct_train / total_train):.2f}% \")\n",
        "    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss1/len(val_loader):.4f}, Val Accuracy: {(100 * correct_val / total_val):.2f}% \")\n",
        "    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss2/len(test_loader):.4f}, Val Accuracy: {(100 * correct_test / total_test):.2f}% \")"
      ],
      "metadata": {
        "id": "QUAuq3mYJ0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this case of vgg16 i got the test accc 97% and valid acc is 97% and train accuracy is 97%. Test accuracy and valid accuractrain accuracy are really very good.This model performs good"
      ],
      "metadata": {
        "id": "0AjvTopI5jPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# resnet50"
      ],
      "metadata": {
        "id": "4Eg0aXCwOwtB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gGqbjRHWOwTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=len(classes)"
      ],
      "metadata": {
        "id": "cDFyofn2BBI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the final layer\n",
        "resnet_model.fc = nn.Sequential(\n",
        "    nn.Linear(resnet_model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(512, num_classes)\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "resnet_model = resnet_model.to(device)"
      ],
      "metadata": {
        "id": "JafdfVvMO4tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnet_model.fc.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OnlpvksnO9hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6icb-gNOv-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "def train_model(model, train_loader, epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "PcZqXmmFPD_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(resnet_model, train_loader, epochs=5)\n",
        "train_model(resnet_model, val_loader, epochs=5)\n",
        "train_model(resnet_model, test_loader, epochs=5)\n"
      ],
      "metadata": {
        "id": "Qw0PwRg4PHg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this case of rsnet50 i got the test accc 95% and valid acc is 94% and train accuracy is 94%. Test accuracy , valid accuracy and train accuracy are really very good.This model performs good"
      ],
      "metadata": {
        "id": "nd3CvG5HpBSK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnktK6leYaL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9URYCgLEPLeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MobileNetV2"
      ],
      "metadata": {
        "id": "IilomyWPiAEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "#Freeze Feature Extractor (Optional)\n",
        "for param in mobilenet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "#Replace the Classifier\n",
        "\n",
        "num_classes = len(train_set.classes)  # Automatically detects classes\n",
        "\n",
        "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
        "#Set Device, Loss, and Optimizer\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mobilenet = mobilenet.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mobilenet.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "uCcx6Wjrh9Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):  # Increase for better accuracy\n",
        "    mobilenet.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mobilenet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = mobilenet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "#val\n",
        "running_loss1 = 0.0\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mobilenet(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "running_loss1 += loss.item()\n",
        "\n",
        "correct1 = 0\n",
        "total1 = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = mobilenet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total1 += labels.size(0)\n",
        "        correct1 += (predicted == labels).sum().item()\n",
        "\n",
        "#test\n",
        "running_loss2 = 0.0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mobilenet(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "running_loss2 += loss.item()\n",
        "\n",
        "correct2 = 0\n",
        "total2 = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = mobilenet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total2 += labels.size(0)\n",
        "        correct2 += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader)}:.4f, train Accuracy: {100 * correct / total:.2f}%\")\n",
        "print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(val_loader)}:.4f, Validation Accuracy: {100 * correct1 / total1:.2f}%\")\n",
        "print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(test_loader)}:.4f, test Accuracy: {100 * correct2 / total2:.2f}%\")"
      ],
      "metadata": {
        "id": "M-PoYut6iZrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2vUPgO7eyyyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this case of MobileNetV2 i got the test accc 92% and valid acc is 90% and train accuracy is 91%. Test accuracy and valid accuracy and train accuracy are really very good.This model performs good"
      ],
      "metadata": {
        "id": "ZcyXeCx5zAjG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Io8diB2h9QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionV3\n"
      ],
      "metadata": {
        "id": "YzpsopxnrKX9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ChmEoqY_sJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from pathlib import Path\n",
        "#from torchvision import transforms\n",
        "\n",
        "transform1 = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),                      # Ensure starting size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shift (10%)\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),      # Random brightness & contrast\n",
        "    transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),       # Random zoom, keep 299√ó299\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "#ImageFolder uses this updated transform:\n",
        "\n",
        "train_set1 = torchvision.datasets.ImageFolder(data_dir.joinpath('train'), transform=transform1)\n",
        "val_set1 = torchvision.datasets.ImageFolder(data_dir.joinpath('val'), transform=transform1)\n",
        "test_set1 = torchvision.datasets.ImageFolder(data_dir.joinpath('test'), transform=transform1)"
      ],
      "metadata": {
        "id": "FMJlhGPY_sjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader1 = DataLoader(train_set1, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader1 = DataLoader(val_set1, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader1 = DataLoader(test_set1, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "hIRlAqHEMV-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zUcMmN_BikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify the Classifier\n",
        "num_classes = 11"
      ],
      "metadata": {
        "id": "S7l-znALBjLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = models.inception_v3(pretrained=True, aux_logits=True)  # Keep aux_logits for training\n",
        "\n",
        "for param in inception.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#Modify the Classifier\n",
        "num_classes = len(train_set1.classes)\n",
        "\n",
        "# Replace the auxiliary classifier (used during training)\n",
        "inception.AuxLogits.fc = nn.Linear(inception.AuxLogits.fc.in_features, num_classes)\n",
        "\n",
        "# Replace the main classifier\n",
        "inception.fc = nn.Linear(inception.fc.in_features, num_classes)\n",
        "\n",
        "#Set Device, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inception = inception.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(inception.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "id": "QGTip2cMrH9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images1, labels1 = next(iter(train_loader1))\n",
        "images1, labels1 = next(iter(val_loader1))\n",
        "images1, labels1 = next(iter(test_loader1))\n",
        "print(images1.shape)  #Should be [batch_size, 3, 299, 299]\n",
        "#Now run training loop\n",
        "\n",
        "#outputs1, aux_outputs1 = inception(images1)"
      ],
      "metadata": {
        "id": "owc4ZlMWEyIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rao1AtUtwl98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#===== Evaluation Function =====\n",
        "def evaluate(loader, name=\"Validation\"):\n",
        "    inception.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images1, labels1 in loader:\n",
        "            images1, labels1 = images1.to(device), labels1.to(device)\n",
        "            outputs = model_v3(images1)\n",
        "            if isinstance(outputs, tuple):  # Only happens if aux logits accidentally appear\n",
        "                outputs = outputs[0]\n",
        "            loss = criterion(outputs, labels1)\n",
        "            running_loss += loss.item() * images1.size(0) # Multiply by batch size for correct average later\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels1).sum().item()\n",
        "            total += labels1.size(0)\n",
        "    acc = correct / total\n",
        "    avg_loss = running_loss / total\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "iZZ9VgBNwm46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    inception.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images1, labels1 in train_loader1:\n",
        "        images1, labels1 = images1.to(device), labels1.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # InceptionV3 returns (main_output, aux_output) during training\n",
        "        outputs, aux_outputs = inception(images1)\n",
        "        loss1 = criterion(outputs, labels1)\n",
        "        loss2 = criterion(aux_outputs, labels1)\n",
        "        loss = loss1 + 0.4 * loss2  # weighted sum\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images1.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels1).sum().item()\n",
        "        total += labels1.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_loss = running_loss / total\n",
        "    val_loss, val_acc = evaluate(val_loader1, \"Validation\")\n",
        "    test_loss, test_acc = evaluate(test_loader1, \"Test\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "diCwRVHaw_qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this case of Inceptionv3 i got the test accc 93% and valid acc is 92%  Test accuracy and valid accuracy and train accuracy are really very good.This model performs good"
      ],
      "metadata": {
        "id": "VbHAEnXS7dtz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWBeU-lairAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB0"
      ],
      "metadata": {
        "id": "GkE_5Id6dvmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(train_set.classes)"
      ],
      "metadata": {
        "id": "MqTH8rWtirE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load EfficientNetB0 Model\n",
        "\n",
        "modelb1 = models.efficientnet_b0(pretrained=True)\n",
        "modelb1.classifier[1] = nn.Linear(modelb1.classifier[1].in_features, num_classes)\n",
        "modelb1 = modelb1.to(device)\n"
      ],
      "metadata": {
        "id": "15bcplDcirLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelb1.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "qBAh-6Cyegmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "for epoch in range(5):  # üîÅ Increase epochs as needed\n",
        "    modelb1.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelb1(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    print(f\"Epoch {epoch+5}, Loss: {running_loss:.4f}, Train Acc: {train_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "gJnHHHPuegdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation on Validation and Test Sets\n",
        "\n",
        "def evaluate(loader, name=\"Validation\"):\n",
        "     optimizer.zero_grad()\n",
        "     outputs = modelb1(images)\n",
        "     loss = criterion(outputs, labels)\n",
        "     loss.backward()\n",
        "     optimizer.step()\n",
        "\n",
        "     running_loss1 += loss.item()\n",
        "     modelb1.eval()\n",
        "     correct1, total1 = 0, 0\n",
        "\n",
        "     with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = modelb1(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct1 += (predicted == labels).sum().item()\n",
        "            total1 += labels.size(0)\n",
        "\n",
        "     acc = correct1 / total1\n",
        "     evaluate(val_loader, \"Validation\")\n",
        "     evaluate(test_loader, \"Test\")\n",
        "     print(f\"Epoch {epoch+5}, Loss: {running_loss1:.4f},{name} Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "bSv1KI0HegZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this case of EfficientNetB0 i got the test accc 94% and valid acc is 93%  Test accuracy and valid accuracy and train accuracy are really very good.This model performs good"
      ],
      "metadata": {
        "id": "JK5tnXNv-bCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transfer Learning\n"
      ],
      "metadata": {
        "id": "OzyqLMzCTPLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fine tune models"
      ],
      "metadata": {
        "id": "M81q4upfNbkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the batch size=32"
      ],
      "metadata": {
        "id": "rjxN9hJ1OUTG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "523kCV0hNbVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "kZLwvifBNbI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader2 = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader2   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader2 = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3R5NupN0NbG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_dataset.classes)"
      ],
      "metadata": {
        "id": "uC6rInXvP5Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vgg16"
      ],
      "metadata": {
        "id": "4G9vz-52P899"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 11  # Change to number of fish classes\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "VJ1WN4DeNbCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16\n",
        "model_16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze feature extractor layers\n",
        "for param in model_16.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify classifier for fish dataset\n",
        "model_16.classifier[6] = nn.Linear(model_16.classifier[6].in_features, num_classes)\n",
        "model_16 = model_16.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_16.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "BfThvlwZNa4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to evaluate accuracy & loss\n",
        "def evaluate(loader):\n",
        "    model_16.eval()\n",
        "    total, correct, running_loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_16(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return running_loss / len(loader), correct / total"
      ],
      "metadata": {
        "id": "e6wRHeruNa00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model_16.train()\n",
        "    train_loss1, total_train1, correct_train1 = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader2:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss1 += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train1 += labels.size(0)\n",
        "        correct_train1 += (predicted == labels).sum().item()\n",
        "\n",
        "    # Validation\n",
        "    val_loss1, val_acc1 = evaluate(val_loader2)\n",
        "    test_loss1, test_acc1 = evaluate(test_loader2)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss1/len(train_loader2):.4f} | Train Acc: {correct_train1/total_train1:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss1:.4f} | Val Acc: {val_acc1:.4f}\")\n",
        "\n",
        "    print(f\"test Loss: {test_loss1:.4f} | test Acc: {test_acc1:.4f}\")"
      ],
      "metadata": {
        "id": "SKq9C8_nS1Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_16.state_dict(), \"vgg16_finetuned.pth\")\n",
        "print(\"Model weights saved as vgg16_finetuned.pth\")"
      ],
      "metadata": {
        "id": "OTUPhRZ7TiGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model rgg16 after fine tune i got val accuracy 97% and test accuracy also 97% which is really very good"
      ],
      "metadata": {
        "id": "RJTELYwkS5kb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5esNgzePRUFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# resnet50"
      ],
      "metadata": {
        "id": "n1yjkgkRRmQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Load Pretrained ResNet50\n",
        "# --------------------------\n",
        "model_50 = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last fc\n",
        "for param in model_50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last FC layer\n",
        "model_50.fc = nn.Linear(model_50.fc.in_features, num_classes)\n",
        "\n",
        "model_50 = model_50.to(device)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Loss & Optimizer\n",
        "# --------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_50.fc.parameters(), lr=0.001)  # Only train last layer\n"
      ],
      "metadata": {
        "id": "B3QYfULCRlTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(loader, model, criterion, name=\"Validation\"):\n",
        "    model_50.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_50(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = correct / total\n",
        "    return running_loss, acc"
      ],
      "metadata": {
        "id": "HwECerBIRUBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model_50.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader2:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_50(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    val_loss, val_acc = evaluate(val_loader2, model_50, criterion, name=\"Validation\")\n",
        "\n",
        "\n",
        "    test_loss, test_acc = evaluate(test_loader2, model_50, criterion, name=\"Test\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "          f\"Train Loss: {running_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "1WmLCTN_RT8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_50.state_dict(), \"resnet50_finetuned.pth\")\n",
        "print(\"Model weights saved as resnet50_finetuned.pth\")"
      ],
      "metadata": {
        "id": "4r2JADelYbsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model resnet50 after fine tune i got val accuracy 97.2% and test accuracy also 97.3% which is really very good"
      ],
      "metadata": {
        "id": "ZuxCX-MsYMPU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05TLJ7IGSd6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mobilenet"
      ],
      "metadata": {
        "id": "2zxezwi8SdL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 11  # Change to number of fish classes\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "GsDbr_U-RT3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2 = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the classifier\n",
        "for param in model_v2.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier for fish dataset\n",
        "model_v2.classifier[1] = nn.Linear(model_v2.classifier[1].in_features, num_classes)\n",
        "model_v2 = model_v2.to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_v2.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "lddh1CvBRTzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(loader, name=\"Validation\"):\n",
        "    model_v2.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_v2(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = correct / total\n",
        "    print(f\"{name} Loss: {running_loss:.4f}, {name} Accuracy: {acc:.4f}\")\n",
        "    return running_loss, acc"
      ],
      "metadata": {
        "id": "5lazwPdnSwyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model_v2.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_v2(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    # Validation\n",
        "    evaluate(val_loader2, name=\"Validation\")\n",
        "\n",
        "    # Final Test Evaluation\n",
        "    evaluate(test_loader2, name=\"Test\")"
      ],
      "metadata": {
        "id": "VBwvle3wSwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_v2.state_dict(), \"mobilenetv2_finetuned.pth\")\n",
        "print(\"Model weights saved as mobilenetv2_finetuned.pth\")"
      ],
      "metadata": {
        "id": "0YgH8k03dS5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model mobilenet_v2 after fine tune i got val accuracy 98.3% and test accuracy also 98.8% which is really very good"
      ],
      "metadata": {
        "id": "5hevuEUbdAyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#InceptionV3"
      ],
      "metadata": {
        "id": "l4qUxOXWTPWh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yk1KHtA9glVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader3 = DataLoader(train_set1, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader3 = DataLoader(val_set1, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader3 = DataLoader(test_set1, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "ubd2UUUVgmJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_set1.classes)\n",
        "\n",
        "# ===== Model =====\n",
        "model_v3 = models.inception_v3(pretrained=True, aux_logits=True)\n",
        "# Replace main FC layer\n",
        "model_v3.fc = nn.Linear(model_v3.fc.in_features, num_classes)\n",
        "# Replace auxiliary FC layer\n",
        "model_v3.AuxLogits.fc = nn.Linear(model_v3.AuxLogits.fc.in_features, num_classes)\n",
        "\n",
        "model_v3 = model_v3.to(device)\n",
        "\n",
        "# ===== Loss & Optimizer =====\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_v3.parameters(), lr=0.0001)\n"
      ],
      "metadata": {
        "id": "f-6x7-l0SwhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#===== Evaluation Function =====\n",
        "def evaluate(loader, name=\"Validation\"):\n",
        "    model_v3.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images1, labels1 in loader:\n",
        "            images1, labels1 = images1.to(device), labels1.to(device)\n",
        "            outputs = model_v3(images1)\n",
        "            if isinstance(outputs, tuple):  # Only happens if aux logits accidentally appear\n",
        "                outputs = outputs[0]\n",
        "            loss = criterion(outputs, labels1)\n",
        "            running_loss += loss.item() * images1.size(0) # Multiply by batch size for correct average later\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels1).sum().item()\n",
        "            total += labels1.size(0)\n",
        "    acc = correct / total\n",
        "    avg_loss = running_loss / total\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "ZZu4pun8TOVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model_v3.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images1, labels1 in train_loader3:\n",
        "        images1, labels1 = images1.to(device), labels1.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # InceptionV3 returns (main_output, aux_output) during training\n",
        "        outputs, aux_outputs = model_v3(images1)\n",
        "        loss1 = criterion(outputs, labels1)\n",
        "        loss2 = criterion(aux_outputs, labels1)\n",
        "        loss = loss1 + 0.4 * loss2  # weighted sum\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images1.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels1).sum().item()\n",
        "        total += labels1.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_loss = running_loss / total\n",
        "    val_loss, val_acc = evaluate(val_loader3, \"Validation\")\n",
        "    test_loss, test_acc = evaluate(test_loader3, \"Test\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "eCmuri0KTOSY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_v3.state_dict(), \"InceptionV3_finetuned.pth\")\n",
        "print(\"Model weights saved as InceptionV3_finetuned.pth\")"
      ],
      "metadata": {
        "id": "SQOW6LWwmh4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model InceptionV3 after fine tune i got val accuracy 99.73% and test accuracy  99.75% which is excellent"
      ],
      "metadata": {
        "id": "jq4AGwDjmECO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNetB0"
      ],
      "metadata": {
        "id": "535cIIsVTuRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model_b0 = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Freeze feature extractor layers (optional for partial fine-tuning)\n",
        "for param in model_b0.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier head\n",
        "model_b0.classifier[1] = nn.Linear(model_b0.classifier[1].in_features, num_classes)\n",
        "\n",
        "model_b0 = model_b0.to(device)\n",
        "\n",
        "# ====== Loss and Optimizer ======\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_b0.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "EhOUsLxdTOH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(loader, name=\"Validation\"):\n",
        "    model_b0.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_b0(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = correct / total\n",
        "    return running_loss, acc"
      ],
      "metadata": {
        "id": "z4bG2Bi6TODF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model_b0.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader2:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_b0(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    val_loss, val_acc = evaluate(val_loader2, \"Validation\")\n",
        "    test_loss, test_acc = evaluate(test_loader2, \"Test\")\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "          f\"Train Loss: {running_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\",f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "CsOMVnLsUO-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_b0.state_dict(), \"EfficientNetB0_finetuned.pth\")\n",
        "print(\"Model weights saved as EfficientNetB0_finetuned.pth\")"
      ],
      "metadata": {
        "id": "Q4N4-6r9z7sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WY86lGQmTNxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained model EfficientNetB0 after fine tune i got val accuracy 98.1% and test accuracy 98.3%  which is excellent"
      ],
      "metadata": {
        "id": "x1NvvnXxzqSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-------------------------------------------------------------------------------------------------------------------\n",
        "#Pretrained model InceptionV3 after fine tune give the high val accuracy 99.73% and test accuracy  99.75%, comparing other models. Which is excellent\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "UaU05D8XtmFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model Evaluation\n",
        "\n",
        "\n",
        "###Evaluate models using metrics like accuracy, precision, recall, F1-score, and confusion matrix.\n"
      ],
      "metadata": {
        "id": "-n3HG1CGvwPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    print(\"Accuracy:\", round(acc, 4))\n",
        "    print(\"Precision:\", round(precision, 4))\n",
        "    print(\"Recall:\", round(recall, 4))\n",
        "    print(\"F1 Score:\", round(f1, 4))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "c6H7l0yzvv6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_ERdXsMbQUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_16, test_loader2,device)"
      ],
      "metadata": {
        "id": "Wk5u6043bS2T",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_50, test_loader2,device)"
      ],
      "metadata": {
        "id": "Xlr0w8auvvt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_v2, test_loader2,device)"
      ],
      "metadata": {
        "id": "2ExpbI400TZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_v3, test_loader3,device)"
      ],
      "metadata": {
        "id": "6po343la0RnI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_b0, test_loader2,device)"
      ],
      "metadata": {
        "id": "7Y3NUxoq0a-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Comparison\n",
        "\n",
        "\n",
        "# Compare results of custom CNN vs pretrained models.\n",
        "\n",
        "\n",
        "#Identify the most accurate, efficient, and reliable model for deployment.\n"
      ],
      "metadata": {
        "id": "1tH2n-lUyKXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Rgg16', 'ResNet50','MobileNetv2','Inceptionv3','EfficientNetb0']\n",
        "accuracies = [97, 97.3,98.8,99.75,98.3]\n",
        "f1_scores = [97, 97,98,99,98]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "bar_width = 0.35\n",
        "x = range(len(models))\n",
        "\n",
        "plt.bar(x, accuracies, width=bar_width, label='Accuracy')\n",
        "plt.bar([i + bar_width for i in x], f1_scores, width=bar_width, label='F1-score')\n",
        "plt.xticks([i + bar_width / 2 for i in x], models)\n",
        "plt.ylabel('Score (%)')\n",
        "plt.title('Model Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqMlnJH0yJAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart compares five models‚ÄîVGG16, ResNet50, MobileNetV2, InceptionV3, and EfficientNetB0‚Äîbased on Accuracy and F1-score. Each model has two bars: blue for Accuracy and orange for F1-score. All models score very close to 99%, showing high and consistent performance. InceptionV3, the model you're working with, performs on par with the others, making it a strong choice. The chart helps visualize which models are most reliable for classification tasks. It‚Äôs a quick way to assess model effectiveness before diving into deeper analysis."
      ],
      "metadata": {
        "id": "0FvUgLbUcmHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future work"
      ],
      "metadata": {
        "id": "GvPFbN6f0nHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In future work, we plan to further optimize hyperparameters such as learning rate, batch size, and dropout rate to maximize performance.\n",
        "Advanced data augmentation techniques like MixUp, CutMix, and AutoAugment will be applied to improve the model‚Äôs generalization ability.\n",
        "We aim to explore ensemble approaches by combining high-performing architectures like EfficientNetB0 and InceptionV3 for better accuracy and stability.\n",
        "Model compression methods such as pruning and quantization will be implemented to enable lightweight deployment on mobile and edge devices.\n",
        "We will also investigate larger model variants and emerging architectures such as Vision Transformers for potential performance gains.\n",
        "Finally, domain adaptation strategies will be explored to ensure robust performance across diverse real-world datasets."
      ],
      "metadata": {
        "id": "i-ZvyLHl0qir"
      }
    }
  ]
}