{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreeproject/AI-/blob/main/ShopperSample_ML_Submission_Template_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Shopper Spectrum: Customer Segmentation and Product Recommendations in E-Commerce\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Type**    - Clustering/Unusupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The global e-commerce industry generates vast amounts of transaction data daily, offering valuable insights into customer purchasing behaviors. Analyzing this data is essential for identifying meaningful customer segments and recommending relevant products to enhance customer experience and drive business growth. This project aims to examine transaction data from an online retail business to uncover patterns in customer purchase behavior, segment customers based on Recency, Frequency, and Monetary (RFM) analysis, and develop a product recommendation system using collaborative filtering techniques."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The global e-commerce industry produces massive transaction data daily, revealing key insights into customer purchasing behavior. This project analyzes online retail data to identify customer segments using Recency, Frequency, and Monetary (RFM) analysis. It also implements a collaborative filtering-based product recommendation system to enhance customer experience and boost business growth."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df=pd.read_csv(\"online_retail.csv\")\n",
        "data_df.head()\n"
      ],
      "metadata": {
        "id": "6MQDwSCdeftY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "FidazFZ1U-P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "3yjiAvcOy91-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "t8ZBue8MVjBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "qZp5W2e-ViUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "aihHLxwVWB30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.columns"
      ],
      "metadata": {
        "id": "mXlkgBb7fo12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.info()"
      ],
      "metadata": {
        "id": "pxW3Cpcgvs9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_ZkjJ8AuMQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 5,268 duplicate rows in the dataset.\n"
      ],
      "metadata": {
        "id": "DKNqmqBmA-Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop duplicate values\n",
        "data_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "0M6FnjKjdIeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "P-jCbF6zdgrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset shape has changed"
      ],
      "metadata": {
        "id": "WK2eZ7tPdxKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values in CustomerID(135037) and description(1454)"
      ],
      "metadata": {
        "id": "dGOMSzC6BHvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Count missing values\n",
        "missing_counts = data_df.isnull().sum()\n",
        "missing_counts = missing_counts[missing_counts > 0]  # Filter only columns with missing values\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "missing_counts.sort_values().plot(kind='barh', color='salmon')\n",
        "plt.title('Count of Missing Values by Column')\n",
        "plt.xlabel('Number of Missing Values')\n",
        "plt.ylabel('Column')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handle Missing Values\n",
        "\n",
        "# Drop rows with missing CustomerID\n",
        "data_df.dropna(subset=['CustomerID'], inplace=True)\n",
        "\n",
        "# Optional: Fill missing 'Description' with placeholder\n",
        "data_df['Description'] =data_df['Description'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "DO1oKCqIoK42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove missing in CustomerID values\n",
        "\n",
        "use fillna('Known') in  Description"
      ],
      "metadata": {
        "id": "nGE260IaBriC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "I4_CETzmAsLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#change dataset shape"
      ],
      "metadata": {
        "id": "MkdhHM_cAyM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset contains 8 fields.They are InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,UnitPrice,Country. Five of them are object types, one is int type and 2 of them are float types. After removing missing columns , duplicated entrys\tand unusal entyrs dataset shape is more than 3lakshs and 8 field are there"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.dtypes"
      ],
      "metadata": {
        "id": "j2F8NtH_c1V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "InvoiceNo - Transaction number\n",
        "\n",
        "StockCode - Unique product/item code\n",
        "\n",
        "Description - Name of the product\n",
        "\n",
        "Quantity -  Number of products purchased\n",
        "\n",
        "InvoiceDate - Date and time of transaction (2022–2023)\n",
        "\n",
        "UnitePrice - Price per product\n",
        "\n",
        "CustomerID - Unique identifier for each customer\n",
        "\n",
        "Country - Country where the customer is based\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "data_df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unusual records."
      ],
      "metadata": {
        "id": "bXBtKSmmlf3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative quantities or unit prices (possible returns or data errors)\n",
        "unusal =data_df[(data_df['Quantity'] <= 0) | (data_df['UnitPrice'] <= 0)]\n",
        "print(unusal.head(10))"
      ],
      "metadata": {
        "id": "hZpstXf2lYu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with negative quantities or unit prices\n",
        "data_df = data_df[(data_df['Quantity'] > 0) & (data_df['UnitPrice'] > 0)]"
      ],
      "metadata": {
        "id": "QXS7rOLqBzob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "JGWHXCD_Cj_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.head()"
      ],
      "metadata": {
        "id": "RbAtA16BCp9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "NAE0aTjnBJcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exclude cancelled invoices (InvoiceNo starting with 'C')"
      ],
      "metadata": {
        "id": "No9UpShVglLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['InvoiceNo'].astype(str).str.startswith('C').sum()"
      ],
      "metadata": {
        "id": "T3Uk6EKNDUTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no invoiceNo starting with 'C'"
      ],
      "metadata": {
        "id": "ZKPyxGjgguuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove cancelled invoices (those with InvoiceNo starting with 'C')\n",
        "#data_df = data_df[~data_df['InvoiceNo'].astype(str).str.startswith('C')]"
      ],
      "metadata": {
        "id": "IpEZ1WnJDuyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.shape"
      ],
      "metadata": {
        "id": "JrUDwd3YDw8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Wrangling containing data loading, data cleaning ,handle missing values, handle duplicate values"
      ],
      "metadata": {
        "id": "fVxIHxuhPjj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['InvoiceDay']= pd.to_datetime(data_df['InvoiceDate']).dt.date\n",
        "data_df['InvoiceMonth'] = pd.to_datetime(data_df['InvoiceDate']).dt.month\n",
        "data_df['InvoiceYear'] = pd.to_datetime(data_df['InvoiceDate']).dt.year"
      ],
      "metadata": {
        "id": "7tb-5_iN0BoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['InvoiceHour'] = pd.to_datetime(data_df['InvoiceDate']).dt.hour"
      ],
      "metadata": {
        "id": "3N23sVnRHptk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column for total price\n",
        "data_df['TotalPrice'] = data_df['Quantity'] * data_df['UnitPrice']\n"
      ],
      "metadata": {
        "id": "qcphMzssHpRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "K6_L0Y_dHMO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA"
      ],
      "metadata": {
        "id": "4iYzv8sPEPzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hi5lgPgCEOln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analyze transaction volume by country\n"
      ],
      "metadata": {
        "id": "XWeS4SpvEJ7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze transaction volume by country\n",
        "transaction_volume = data_df.groupby('Country')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "\n",
        "# Plot the top 20 countries by transaction volume\n",
        "plt.figure(figsize=(12, 6))\n",
        "transaction_volume.head(20).plot(kind='bar', color='skyblue')\n",
        "plt.title('Top 20 Countries by Transaction Volume')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of Unique Invoices')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show the top 10 countries in the console\n",
        "print(transaction_volume.head(20))"
      ],
      "metadata": {
        "id": "3798d52GEVA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights the top 20 countries by their number of unique invoice transactions. The United Kingdom leads with an exceptionally high volume, indicating a dominant market presence. Germany, France, and Ireland follow, while countries like Japan and Australia show modest engagement. Overall, the data suggests opportunities for expansion in underrepresented regions."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify top-selling products"
      ],
      "metadata": {
        "id": "kX5QjyAtUXEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by product description and sum total products\n",
        "top_products = data_df.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False) #TotalPrice = Quantity * UnitPrice\n",
        "\n",
        "# Plot the top 15 best-selling products by revenue\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_products.head(15).plot(kind='bar', color='orange')\n",
        "plt.title('Top 15 Best-Selling Products by Revenue')\n",
        "plt.xlabel('Product Description')\n",
        "plt.ylabel('Total Sales (£)')\n",
        "plt.xticks(rotation=75)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display top 15 products in the console\n",
        "print(top_products.head(15))"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph shows the top 15 products ranked by revenue, based on total sales in British pounds. \"PAPER CRAFT , LITTLE BIRDIE\" generates the highest revenue, followed by the \"REGENCY CAKESTAND 3 TIER\" and \"WHITE HANGING HEART T-LIGHT HOLDER.\" Each product's sales are illustrated with orange bars, where taller bars indicate higher revenue. The chart helps identify the most financially successful items in the product lineup."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart 3"
      ],
      "metadata": {
        "id": "lwshINdt389Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify Top 10 Customers"
      ],
      "metadata": {
        "id": "Xce7siGq4Bph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data_df['TotalPrice'] = data_df['Quantity'] * data_df['UnitPrice']\n",
        "top_customers = data_df.groupby('CustomerID')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_customers.values, y=top_customers.index, palette='viridis')\n",
        "plt.title(\"Top 10 Most Buying Customers (by Spend)\")\n",
        "plt.xlabel(\"Total Spend\")\n",
        "plt.ylabel(\"CustomerID\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "top_customers.head(10)"
      ],
      "metadata": {
        "id": "tESU6U2c3TX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph ranks the top 10 customers by total spend in GBP, with each bar representing a different CustomerID. The leading customer spent around £280,000, significantly more than the others. Spending decreases steadily down the list, with the tenth customer spending just above £77,000. This visualization helps identify key revenue-driving clients who may benefit from personalized engagement or loyalty initiatives."
      ],
      "metadata": {
        "id": "8u9JodBiSVl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize purchase trends over time\n"
      ],
      "metadata": {
        "id": "Rh1by3rdWU1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Convert InvoiceDate to datetime\n",
        "data_df['InvoiceDate'] = pd.to_datetime(data_df['InvoiceDate'])\n",
        "\n",
        "# Extract only the date part (ignore time)\n",
        "data_df['InvoiceDay'] = data_df['InvoiceDate'].dt.date\n",
        "\n",
        "# Group by day and sum total price\n",
        "daily_sales = data_df.groupby('InvoiceDay')['TotalPrice'].sum()\n",
        "\n",
        "# Plot purchase trend over time\n",
        "plt.figure(figsize=(14, 6))\n",
        "daily_sales.plot(color='green')\n",
        "plt.title('Daily Purchase Trend Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales (£)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graph shows how much money people spent each day in 2023. Sometimes sales went up and down, but overall, they kept growing over time. Toward the end of the year, people spent a lot more—over £175,000 in a day. This likely happened because of sales or holidays when people buy more."
      ],
      "metadata": {
        "id": "uV1rCb6xTm2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inspect monetary distribution per transaction and customer"
      ],
      "metadata": {
        "id": "3bQNU7fQXj8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Total sales per transaction (InvoiceNo)\n",
        "invoice_totals = data_df.groupby('InvoiceNo')['TotalPrice'].sum()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.histplot(invoice_totals, bins=100, kde=True, color='blue')\n",
        "plt.title('Monetary Distribution per Transaction')\n",
        "plt.xlabel('Total Value per Invoice (£)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph, a histogram with a kernel density estimate (KDE), shows the distribution of monetary values for each transaction. The vast majority of transactions have a very low total value, as indicated by the tall bar and high peak on the far left. As the transaction value increases, the frequency of those transactions drops off sharply. The long tail to the right shows that while very high-value transactions are rare, they do occur."
      ],
      "metadata": {
        "id": "TjH82VySUEtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#which day of the week had the most product sales (by quantity)"
      ],
      "metadata": {
        "id": "79dbfl7G5or8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract weekday (0=Monday, 6=Sunday)\n",
        "data_df['Weekday'] = data_df['InvoiceDate'].dt.day_name()\n",
        "\n",
        "# Total quantity sold per day\n",
        "sales_by_day = data_df.groupby('Weekday')['Quantity'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Order days properly\n",
        "ordered_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "sales_by_day = sales_by_day.reindex(ordered_days)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=sales_by_day.index, y=sales_by_day.values, palette='mako')\n",
        "plt.title('Total Product Quantity Sold by Day of the Week')\n",
        "plt.ylabel('Total Quantity Sold')\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "sales_by_day.head(7)"
      ],
      "metadata": {
        "id": "4I77IPJH5pb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows which days of the week had the most product sales. Friday is the busiest day, with over a million items sold. Monday is the slowest, with only about half a million sold. Most other days like Wednesday and Thursday also had high sales, while Sunday isn’t shown at all."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RFM distributions"
      ],
      "metadata": {
        "id": "P5Um0CZFaQw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Set reference date for Recency (usually one day after the last transaction)\n",
        "reference_date = data_df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
        "\n",
        "# Group by Customer and compute RFM\n",
        "rfm = data_df.groupby('CustomerID').agg({\n",
        "    'InvoiceDate': lambda x: (reference_date - x.max()).days,  # Recency\n",
        "    'InvoiceNo': 'nunique',                                    # Frequency\n",
        "    'TotalPrice': 'sum'                                        # Monetary\n",
        "}).reset_index()\n",
        "\n",
        "# Rename columns\n",
        "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
        "\n",
        "# ---- Visualize RFM Distributions ----\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Recency\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(rfm['Recency'], bins=50, kde=True, color='green')\n",
        "plt.title('Recency Distribution')\n",
        "plt.xlabel('Days Since Last Purchase')\n",
        "\n",
        "# Frequency\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.histplot(rfm['Frequency'], bins=50, kde=True, color='blue')\n",
        "plt.title('Frequency Distribution')\n",
        "plt.xlabel('Number of Transactions')\n",
        "\n",
        "# Monetary\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.histplot(rfm['Monetary'], bins=50, kde=True, color='purple')\n",
        "plt.title('Monetary Distribution')\n",
        "plt.xlabel('Total Spend (£)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recency Distribution:-\n",
        "This shows how recently customers made their last purchase. Most customers bought something within the past 50 days, and fewer as you move closer to 400 days. It helps identify how engaged your customer base is—more recent purchases often mean stronger loyalty."
      ],
      "metadata": {
        "id": "CQMDXAzGU-E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency Distribution:-This tracks how often customers make purchases. Most shoppers made fewer than 10 transactions, while very few made over 100. It highlights that your business has many occasional buyers, with a small group of repeat customers."
      ],
      "metadata": {
        "id": "gVFc1IzDVHls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monetary Distribution:-This displays how much money each customer spent in total. Most people spent relatively little, and only a few spent tens of thousands of pounds.\n",
        "It suggests the presence of high-value customers alongside many low-spend ones."
      ],
      "metadata": {
        "id": "Hx3_YP_aVbR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM analysis is a marketing technique that evaluates customers based on:\n",
        "\n",
        "#Recency – How recently a customer purchased.\n",
        "\n",
        "#Frequency – How often they purchased.\n",
        "\n",
        "#Monetary value – How much money they spent.\n",
        "\n",
        "RFM analysis is used to segment customers, understand their value, and build targeted campaigns to improve retention, loyalty, and revenue.\n",
        "\n",
        "Recency\n",
        "\n",
        "Definition: Number of days since the customer's last transaction.\n",
        "\n",
        "Logic: More recent customers are more likely to buy again.\n",
        "\n",
        "Formula:\n",
        "\n",
        "#Recency = Reference Date − Last Purchase Date\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Frequency\n",
        "\n",
        "Definition: Number of distinct purchases the customer made.\n",
        "\n",
        "Logic: Frequent customers are more loyal.\n",
        "\n",
        "Formula:\n",
        "\n",
        "#Frequency = Number of Unique Orders (Invoices)\n",
        "\n",
        "\n",
        "Monetary\n",
        "\n",
        "Definition: Total money the customer has spent.\n",
        "\n",
        "Logic: High-spending customers bring more value.\n",
        "\n",
        "Formula:\n",
        "\n",
        "#Monetary = ∑ (Quantity × Unit Price)\n",
        "\n"
      ],
      "metadata": {
        "id": "iOun8n3PKWdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "glKUY7rgWDxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_iqr(df, columns):\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    return df"
      ],
      "metadata": {
        "id": "kqncU8i6tt_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_cleaned = remove_outliers_iqr(rfm, ['Recency', 'Frequency', 'Monetary'])\n"
      ],
      "metadata": {
        "id": "HNd1OMSXt31d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "for i, col in enumerate(['Recency', 'Frequency', 'Monetary']):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    sns.boxplot(y=rfm[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "slPF9_52t8aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f7g08a57WD1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use Log Transformation to handle these outliers. Because rfm values are highly  right skewed"
      ],
      "metadata": {
        "id": "R7VeuVuo_x4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Log Transformation\n",
        "\n",
        "# Select the columns to apply log transformation\n",
        "rfm_cols= ['Recency', 'Frequency', 'Monetary']\n",
        "\n",
        "# Create a copy to avoid modifying the original rfm DataFrame directly if needed later\n",
        "rfm_log = rfm[rfm_cols].copy()\n",
        "\n",
        "# Apply log transformation using np.log1p (log(1+x) to handle zero values)\n",
        "rfm_log['Recency'] = np.log1p(rfm_log['Recency'])\n",
        "rfm_log['Frequency'] = np.log1p(rfm_log['Frequency'])\n",
        "rfm_log['Monetary'] = np.log1p(rfm_log['Monetary'])\n",
        "\n",
        "# Display the first few rows of the transformed data to check\n",
        "print(rfm_log.head())"
      ],
      "metadata": {
        "id": "8GVd2X0D_wa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Standardize/Normalize the RFM values code"
      ],
      "metadata": {
        "id": "Mfnq5OmSwgkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled1 = scaler.fit_transform(rfm_log[['Recency', 'Frequency', 'Monetary']])\n",
        "\n",
        "# Convert back to DataFrame\n",
        "rfm_scaled_df = pd.DataFrame(rfm_scaled1, columns=['Recency', 'Frequency', 'Monetary'], index=rfm_log.index)"
      ],
      "metadata": {
        "id": "vesi850Dy9_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Elbow curve for cluster selection"
      ],
      "metadata": {
        "id": "XNs2HU5sM1wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming you already have the RFM dataframe ready\n",
        "# Columns: Recency, Frequency, Monetary\n",
        "\n",
        "# Step 1: Normalize RFM values\n",
        "#scaler = StandardScaler()\n",
        "#rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])\n",
        "\n",
        "# Step 2: Calculate WCSS (within-cluster sum of squares) for different k\n",
        "wcss = []\n",
        "K = range(1, 11)\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(rfm_scaled1)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Step 3: Plot the Elbow Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K, wcss, marker='o')\n",
        "plt.title('Elbow Curve for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('WCSS')\n",
        "plt.xticks(K)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Elbow Curve helps determine the optimal number of clusters (k) for segmentation. As k increases, the Within-Cluster Sum of Squares (WCSS) decreases sharply at first, indicating better fit. Around k=3, the curve begins to flatten, forming the “elbow”—this suggests adding more clusters yields diminishing returns. So, k=3 is a likely sweet spot where you balance granularity with simplicity."
      ],
      "metadata": {
        "id": "BsgEZc1cYWv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Customer cluster profiles"
      ],
      "metadata": {
        "id": "zzXckXwvOPaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Apply KMeans with chosen number of clusters (example: 4)\n",
        "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
        "rfm['Cluster'] = kmeans.fit_predict(rfm_scaled1)\n",
        "rfm['Cluster']"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Profile Each Cluster\n",
        "# Calculate average RFM values per cluster\n",
        "cluster_profile = rfm.groupby('Cluster').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean',\n",
        "    'CustomerID': 'count'\n",
        "}).rename(columns={'CustomerID': 'Num_Customers'}).round(1).reset_index()\n",
        "\n",
        "print(cluster_profile)"
      ],
      "metadata": {
        "id": "WuoyrIZhOzDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #2D plot of Frequency vs Recency\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=rfm, x='Recency', y='Frequency', hue='Cluster', palette='Set2')\n",
        "plt.title('Customer Segments: Recency vs Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dST8Mux3PHam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scatter plot segments customers by their recent activity and shopping frequency. Cluster 1 (orange) highlights loyal buyers who shop frequently and have purchased recently. Clusters 2 and 3 (blue and pink) represent moderate or occasional customers with varying engagement. Cluster 0 (green) includes mostly inactive users who haven’t purchased recently and do so infrequently."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Product recommendation heatmap / similarity matrix\n"
      ],
      "metadata": {
        "id": "vi592QPaQCG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Create a Customer-Product Matrix\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Create a pivot table of customers and products with quantity as values\n",
        "product_matrix = data_df.pivot_table(index='CustomerID', columns='Description', values='Quantity', aggfunc='sum', fill_value=0)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Product Similarity\n",
        "\n",
        "# Transpose: we want product-by-product similarity\n",
        "product_similarity = cosine_similarity(product_matrix.T)\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "product_similarity_df = pd.DataFrame(product_similarity,\n",
        "                                     index=product_matrix.columns,\n",
        "                                     columns=product_matrix.columns)"
      ],
      "metadata": {
        "id": "DW4YT2ThQe39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Heatmap\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a subset of top products for visualization\n",
        "top_products = product_matrix.sum().sort_values(ascending=False).head(10).index\n",
        "subset_sim = product_similarity_df.loc[top_products, top_products]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(subset_sim, cmap='YlGnBu', annot=True, fmt=\".2f\")\n",
        "plt.title(\"Product Similarity Heatmap (Top 10 Products)\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FGSYAeznQ02o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This heatmap illustrates the similarity scores between the top 10 products based on customer behavior or product attributes. Darker blue cells represent high similarity, suggesting those items are often bought together or share key features. Lighter yellow regions indicate low similarity, meaning those products rarely relate or co-occur. Businesses can use this data to recommend items, optimize product placement, or design bundled offerings."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "features = ['Quantity', 'UnitPrice', 'TotalPrice', 'InvoiceNo' ,'CustomerID' ]\n",
        "correlation_matrix = data_df[features].corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This correlation heatmap shows relationships between variables like Quantity, UnitPrice, TotalPrice, InvoiceNo, and CustomerID. Strong red areas indicate high positive correlations—most notably between Quantity and TotalPrice (0.91), meaning buying more items tends to raise the total price. Blue regions suggest weak or negative correlations, such as InvoiceNo or CustomerID having little relevance to pricing. These insights help pinpoint which features strongly influence revenue and which are mostly identifiers."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(rfm, vars=['Recency', 'Frequency', 'Monetary'], hue='Cluster', palette='Set2')\n",
        "plt.suptitle(\"Pair Plot of RFM Features by Cluster\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pair plot shows how customers are distributed across clusters based on RFM—Recency, Frequency, and Monetary values. Diagonal panels display the feature distributions per cluster, revealing patterns like Cluster 1 (blue) having low recency and high frequency/spending, indicating loyal customers. Off-diagonal scatter plots show relationships between features, such as how higher frequency often aligns with higher monetary value. The color-coded clusters highlight distinct customer types, making it easier to tailor engagement strategies for each group."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handled missing values by removing 135,037 rows with missing CustomerID using .dropna(), and filled 1,454 missing entries in the Description column with 'unknown' using .fillna('unknown')."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2vDGYwrPAuqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_scaled_df.head()"
      ],
      "metadata": {
        "id": "O4lEUuckE-09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To support customer segmentation and product recommendation, we engineered several new features. First, we extracted detailed time-based features from the InvoiceDate column, such as year, month, day, and hour.\n",
        "\n",
        "These features help in analyzing customer behavior trends over different time periods. Next, we created a new feature called TotalPrice by multiplying Quantity and UnitPrice, giving the total transaction value for each order line. This allows us to quantify how much customers spend in each transaction.\n",
        "\n",
        "This new feature helps in understanding customer spending behavior and plays a crucial role in RFM (Recency, Frequency, Monetary) analysis and revenue-based segmentation."
      ],
      "metadata": {
        "id": "5SWiDJrde1RU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U8Rge6j4mfok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # ML Model Implementation"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Clustering Algorithms"
      ],
      "metadata": {
        "id": "lAhUw1-6z7vf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.KMeans + Silhouette Score"
      ],
      "metadata": {
        "id": "BcuN2T-c0NUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KMeans + Silhouette Score\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Assume rfm_scaled is your standardized/normalized RFM data\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "labels = kmeans.fit_predict(rfm_scaled1)\n",
        "rfm['Kmean_Cluster+Silhouette Score'] =labels\n",
        "\n",
        "# Calculate silhouette score\n",
        "score = silhouette_score(rfm_scaled1, labels)\n",
        "\n",
        "print(f\"Silhouette Score for k=4: {score:.4f}\")"
      ],
      "metadata": {
        "id": "2yHLgYAHzKBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To Find Optimal k Using Silhouette Score\n",
        "\n",
        "scores = []\n",
        "k_values = range(2, 11)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(rfm_scaled1)\n",
        "    score = silhouette_score(rfm_scaled1, labels)\n",
        "    scores.append(score)\n",
        "    print(f\"k={k}, Silhouette Score={score:.4f}\")"
      ],
      "metadata": {
        "id": "7L4-SVyRJzjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot it\n",
        "\n",
        "plt.plot(k_values, scores, marker='o')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for different k')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQeMLuSjJza5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph displays the Silhouette Score for different cluster counts (k), helping evaluate how well data points are grouped.\n",
        "k=3 is initial choice for clustering. In that case, the graph shows that k=2 offers better cohesion with a higher Silhouette Score, suggesting tighter and more distinct clusters. However, sticking with k=3 might still be justified if it aligns better with domain-specific needs, like separating subtle customer segments.This helps choose the best cluster number by balancing simplicity and segmentation accuracy."
      ],
      "metadata": {
        "id": "HoPMvmph0e-E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QfAqO9QwKtz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.KMeans+Elbow Method"
      ],
      "metadata": {
        "id": "yShQOq3d0jpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Elbow Method Code\n",
        "\n",
        "# Inertia values list\n",
        "inertia = []\n",
        "K = range(1, 11)  # Trying k from 1 to 10\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    kmeans.fit(rfm_scaled1)\n",
        "    inertia.append(kmeans.inertia_) # Add this line back to append inertia to the list\n",
        "\n",
        "    print(f\"k={k}, inertia = {inertia[-1]:.4f}\")"
      ],
      "metadata": {
        "id": "wWhhMgRpz-Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head()"
      ],
      "metadata": {
        "id": "N_d0OvF0iDAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Elbow Curve\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(K, inertia, marker='o') # Changed 'k' to 'K' to plot the list of k values\n",
        "plt.title('Elbow Method - Optimal k')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Inertia (SSE)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uSs3v_NzKuHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph represents the Elbow Method for selecting the optimal number of clusters (k) in a dataset using k-means. As the number of clusters increases, the inertia (sum of squared errors) decreases, indicating tighter grouping. However, after a certain point—around k=3 or k=4—the rate of improvement drops, forming an “elbow” in the curve. This elbow marks the balance point where adding more clusters yields minimal benefit in reducing inertia. Choosing k at this elbow ensures efficient clustering without unnecessarily increasing model complexity."
      ],
      "metadata": {
        "id": "rjbrzAZMjHuC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXq6kmxgOczT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # DBScan"
      ],
      "metadata": {
        "id": "UeuUuoIL3E_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# eps and min_samples are hyperparameters you can tune\n",
        "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
        "rfm['DBSCAN_Cluster'] = dbscan.fit_predict(rfm_scaled1)\n",
        "\n",
        "print(rfm['DBSCAN_Cluster'].value_counts())"
      ],
      "metadata": {
        "id": "6Ni-817qO1Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize DBSCAN Clusters\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.scatterplot(\n",
        "    x=rfm_scaled1[:, 0], y=rfm_scaled1[:, 1],\n",
        "    hue=rfm['DBSCAN_Cluster'],\n",
        "    palette='Set1'\n",
        ")\n",
        "plt.title(\"DBSCAN Clusters\")\n",
        "plt.xlabel(\"Recency (scaled)\")\n",
        "plt.ylabel(\"Frequency (scaled)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXa0Dd9p1GGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scatter plot displays the DBSCAN clustering results based on scaled Recency and Frequency values. The blue points (Cluster 0) represent the main group of customers with varying purchase frequencies and recent activity. The red points (Cluster -1) are classified as outliers, indicating unusual purchasing patterns compared to the main cluster. This visualization helps identify customer segments as well as exceptions that may require special marketing or investigation."
      ],
      "metadata": {
        "id": "IzAu1GRcjht0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RFHmQQdi9NmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchial"
      ],
      "metadata": {
        "id": "UNc0dpya9JuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Linkage and Plot Dendrogram\n",
        "\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "dendrogram = sch.dendrogram(sch.linkage(rfm_scaled1, method='ward'))\n",
        "plt.title(\"Customer Dendrogram\")\n",
        "plt.xlabel(\"Customer Index\")\n",
        "plt.ylabel(\"Euclidean Distance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4tkC5AZV9JKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph is a dendrogram created from hierarchical clustering of customer data, often used for segmentation analysis.\n",
        "\n",
        "It visually shows how individual customers are grouped based on similarity, using Euclidean distance as a measure.\n",
        "\n",
        "As you move up the vertical axis, the lines joining data points represent clusters being merged—shorter merges indicate more similar customers.\n",
        "\n",
        "The “branches” and colored clusters reveal how customers naturally form distinct groups, which can help in designing targeted marketing strategies.\n",
        "\n",
        "By choosing a horizontal cut (e.g., where the biggest vertical gaps occur), you can decide how many final clusters to create, such as 3 or 4 meaningful groups."
      ],
      "metadata": {
        "id": "TjrARhP8kVq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Agglomerative Clustering\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "hc = AgglomerativeClustering(n_clusters=4, metric='euclidean', linkage='ward') #metric='euclidean' is used for distance calculation.\n",
        "                                                                               #linkage='ward' only works with Euclidean distance, so make sure metric='euclidean'\n",
        "rfm['Hierarchical_Cluster'] = hc.fit_predict(rfm_scaled1)\n",
        "\n",
        "print(rfm['Hierarchical_Cluster'].value_counts())"
      ],
      "metadata": {
        "id": "53NBX8GK1Fya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhbBGU0Q1FrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Label the clusters by interpreting their RFM averages:"
      ],
      "metadata": {
        "id": "V9xvh-NfGv7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recency – How recently a customer purchased.\n",
        "\n",
        "Frequency – How often they purchased.\n",
        "\n",
        "Monetary value – How much money they spent."
      ],
      "metadata": {
        "id": "GyKfT10cE2my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label the clusters by interpreting their RFM averages:\n",
        "\n",
        "\n",
        "\n",
        "Cluster  --   Characteristics     --        Segment Label\n",
        "\n",
        "High R,\n",
        "High F,\n",
        "High M  --  Regular, frequent, recent,\n",
        "                and big spenders  --        High-Value\n",
        "\n",
        "\n",
        "Medium F,\n",
        "Medium M --  Steady purchasers but not\n",
        "             premium                    --     Regular\n",
        "\n",
        "Low F,\n",
        "Low M,\n",
        "older R --    Rare, occasional purchases --   Occasional\n",
        "High R,\n",
        "\n",
        "Low F,\n",
        "Low M    --  Haven’t purchased in a long time -- At-Risk\n",
        "\n"
      ],
      "metadata": {
        "id": "BA6wMlSDE2ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group by Cluster and Calculate Mean RFM Values\n",
        "\n",
        "rfm_cluster_avg = rfm.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean().round(1)\n",
        "print(rfm_cluster_avg)"
      ],
      "metadata": {
        "id": "6mLNAvrLBQOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original segment labels\n",
        "segment_labels = {\n",
        "    0: 'Regular',\n",
        "    1: 'Occasional',\n",
        "    2: 'High-Value',\n",
        "    3: 'At-Risk',\n",
        "}\n",
        "\n",
        "\n",
        "# First map the known cluster numbers\n",
        "rfm['Segment'] = rfm['Cluster'].map(segment_labels)\n"
      ],
      "metadata": {
        "id": "_m7rBbMhEABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KMeans – Most commonly used for RFM segmentation"
      ],
      "metadata": {
        "id": "VA8xi_2KI2JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rfm[['CustomerID', 'Cluster', 'Segment']].head(10))"
      ],
      "metadata": {
        "id": "hoeqQb8ID98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rfm['Segment'].value_counts())"
      ],
      "metadata": {
        "id": "FDlduUVzNRB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.head(10)"
      ],
      "metadata": {
        "id": "JQzYos4uJPj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low recency,high frequency and high monetary"
      ],
      "metadata": {
        "id": "8fj2SabWO0lM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMw59ZpL2i2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3D Plot Compari\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "# Elbow 3D\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "sc = ax.scatter(rfm['Recency'], rfm['Frequency'], rfm['Monetary'],\n",
        "                c=rfm['Cluster'], cmap='Set2', s=50)\n",
        "ax.set_title(\"Elbow Clusters\")\n",
        "ax.set_xlabel(\"Recency\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_zlabel(\"Monetary\")\n",
        "\n",
        "# Silhouette 3D\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "sc = ax.scatter(rfm['Recency'], rfm['Frequency'], rfm['Monetary'],\n",
        "                c=rfm['Kmean_Cluster+Silhouette Score'], cmap='Set1', s=50)\n",
        "ax.set_title(\"Silhouette Clusters\")\n",
        "ax.set_xlabel(\"Recency\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_zlabel(\"Monetary\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OprqaEEkOcdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These 3D scatter plots compare customer segmentation results using the Elbow and Silhouette methods. Each method groups customers based on Recency, Frequency, and Monetary values, with different colors representing distinct clusters. This visual comparison helps evaluate how well-separated and meaningful the clusters are for targeted analysis."
      ],
      "metadata": {
        "id": "-M0S-ybUqPrR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpOkbUDEKuLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean()"
      ],
      "metadata": {
        "id": "Gf_hdCELQBWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qMUV3vHUbybb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFTu6pu0bx_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.groupby(rfm['Kmean_Cluster+Silhouette Score'])[['Recency', 'Frequency', 'Monetary']].mean()"
      ],
      "metadata": {
        "id": "aeh4su9BgJcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot 3D Clusters\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Assign x, y, z from the original RFM features (unscaled or scaled)\n",
        "x = rfm_scaled1[:, 0]  # Recency\n",
        "y = rfm_scaled1[:, 1]  # Frequency\n",
        "z = rfm_scaled1[:, 2]  # Monetary\n",
        "\n",
        "# Plot\n",
        "scatter = ax.scatter(x, y, z, c=rfm['DBSCAN_Cluster'], cmap='Set1', s=60)\n",
        "\n",
        "# Axis labels\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "\n",
        "# Legend\n",
        "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.title(\"3D DBSCAN Clusters on RFM\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BOEV3_Avb0HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This 3D plot shows customer segmentation results using DBSCAN applied to RFM (Recency, Frequency, Monetary) metrics. Cluster 0 (gray) includes customers with similar purchasing behavior, forming a dense core group. Cluster -1 (red) represents outliers—customers whose patterns differ significantly from the main segments. DBSCAN is particularly useful here because it detects clusters of varying shapes and isolates noise without requiring the number of clusters beforehand."
      ],
      "metadata": {
        "id": "-jLCF-NYqcZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.groupby(rfm['DBSCAN_Cluster'])[['Recency', 'Frequency', 'Monetary']].mean()"
      ],
      "metadata": {
        "id": "5-MhMb84b0qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVwY7FGEb0an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kJJOA8MidPFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract scaled RFM features\n",
        "x = rfm_scaled1[:, 0]  # Recency\n",
        "y = rfm_scaled1[:, 1]  # Frequency\n",
        "z = rfm_scaled1[:, 2]  # Monetary\n",
        "\n",
        "# Plot\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(x, y, z, c=rfm['Hierarchical_Cluster'], cmap='tab10', s=60)\n",
        "\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "ax.set_title('Hierarchical Clustering - 3D View')\n",
        "\n",
        "# Legend\n",
        "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jjepI4EadPw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This 3D plot displays customer segmentation using hierarchical clustering based on Recency, Frequency, and Monetary metrics. Each color represents a distinct group with similar purchasing behavior and engagement patterns. The spatial separation highlights differences, such as high spenders clustered away from occasional buyers. This segmentation helps businesses personalize marketing and improve retention strategies."
      ],
      "metadata": {
        "id": "nztXdloPqoQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm.groupby(rfm['Hierarchical_Cluster'])[['Recency', 'Frequency', 'Monetary']].mean()"
      ],
      "metadata": {
        "id": "8sML2BR5dtGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans Clustering as the final model for customer segmentation. It is efficient, scalable, and suitable for handling large transactional datasets. The algorithm works effectively with RFM (Recency, Frequency, Monetary) features after normalization. KMeans provides clear and interpretable customer clusters that support business decision-making. The optimal number of clusters was determined using the Elbow Method to balance accuracy and simplicity. This model successfully grouped customers into meaningful segments like High-Value, Regular, Occasional, and At-Risk."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    }
  ]
}